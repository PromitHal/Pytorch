{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport os\nfrom glob import glob\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model, load_model, save_model ,Sequential\nfrom tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D,MaxPooling2D, concatenate, Dense, Flatten, UpSampling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import backend as K","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-03T22:34:20.613692Z","iopub.execute_input":"2022-07-03T22:34:20.614308Z","iopub.status.idle":"2022-07-03T22:34:26.521114Z","shell.execute_reply.started":"2022-07-03T22:34:20.614227Z","shell.execute_reply":"2022-07-03T22:34:26.520114Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"root_dir='../input/sun-segmented/mask_123'\nroot_polyps='../input/sun-segmented/mask_123'\nroot_annotations='../input/sun-polyps/annotation_csv'","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:34:26.522934Z","iopub.execute_input":"2022-07-03T22:34:26.523629Z","iopub.status.idle":"2022-07-03T22:34:26.532295Z","shell.execute_reply.started":"2022-07-03T22:34:26.523590Z","shell.execute_reply":"2022-07-03T22:34:26.530032Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"less_more_data=pd.read_csv('../input/less-more-5/less_more.csv')\nless_more_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:34:26.534386Z","iopub.execute_input":"2022-07-03T22:34:26.535036Z","iopub.status.idle":"2022-07-03T22:34:26.573369Z","shell.execute_reply.started":"2022-07-03T22:34:26.534998Z","shell.execute_reply":"2022-07-03T22:34:26.572393Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Less5                  More5\n0              3            1.0\n1              4            2.0\n2              5            7.0\n3              6           12.0\n4              9           23.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Less5</th>\n      <th>More5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>7.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>6</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>23.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import cv2\nimport torch\nimport urllib.request\n\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:34:26.576352Z","iopub.execute_input":"2022-07-03T22:34:26.576972Z","iopub.status.idle":"2022-07-03T22:34:28.299506Z","shell.execute_reply.started":"2022-07-03T22:34:26.576936Z","shell.execute_reply":"2022-07-03T22:34:28.298551Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"pip install timm","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:34:28.300754Z","iopub.execute_input":"2022-07-03T22:34:28.301146Z","iopub.status.idle":"2022-07-03T22:34:45.038620Z","shell.execute_reply.started":"2022-07-03T22:34:28.301111Z","shell.execute_reply":"2022-07-03T22:34:45.036048Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting timm\n  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.5/431.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm) (0.12.0)\nRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm) (1.11.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm) (4.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (1.21.6)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (9.1.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision->timm) (2.27.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm) (2.0.12)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm) (1.26.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm) (2022.6.15)\nInstalling collected packages: timm\nSuccessfully installed timm-0.5.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"model_type = \"DPT_Large\"     # MiDaS v3 - Large     (highest accuracy, slowest inference speed)\n#model_type = \"DPT_Hybrid\"   # MiDaS v3 - Hybrid    (medium accuracy, medium inference speed)\n#model_type = \"MiDaS_small\"  # MiDaS v2.1 - Small   (lowest accuracy, highest inference speed)\n\nmidas = torch.hub.load(\"intel-isl/MiDaS\", model_type)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:36:24.259384Z","iopub.execute_input":"2022-07-03T22:36:24.259732Z","iopub.status.idle":"2022-07-03T22:36:46.154123Z","shell.execute_reply.started":"2022-07-03T22:36:24.259702Z","shell.execute_reply":"2022-07-03T22:36:46.152965Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\nDownloading: \"https://github.com/intel-isl/DPT/releases/download/1_0/dpt_large-midas-2f21e586.pt\" to /root/.cache/torch/hub/checkpoints/dpt_large-midas-2f21e586.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0.00/1.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fb4a44f1a9a40e79a49f2ed22822f14"}},"metadata":{}}]},{"cell_type":"code","source":"midas_transforms = torch.hub.load(\"intel-isl/MiDaS\", \"transforms\")\n\nif model_type == \"DPT_Large\" or model_type == \"DPT_Hybrid\":\n    transform = midas_transforms.dpt_transform\nelse:\n    transform = midas_transforms.small_transform","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:36:46.156404Z","iopub.execute_input":"2022-07-03T22:36:46.157109Z","iopub.status.idle":"2022-07-03T22:36:46.813501Z","shell.execute_reply.started":"2022-07-03T22:36:46.157064Z","shell.execute_reply":"2022-07-03T22:36:46.812481Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmidas.to(device)\nmidas.eval()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:36:46.814836Z","iopub.execute_input":"2022-07-03T22:36:46.815201Z","iopub.status.idle":"2022-07-03T22:36:53.329417Z","shell.execute_reply.started":"2022-07-03T22:36:46.815165Z","shell.execute_reply":"2022-07-03T22:36:53.328440Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DPTDepthModel(\n  (pretrained): Module(\n    (model): VisionTransformer(\n      (patch_embed): PatchEmbed(\n        (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n        (norm): Identity()\n      )\n      (pos_drop): Dropout(p=0.0, inplace=False)\n      (blocks): Sequential(\n        (0): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (1): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (2): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (3): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (4): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (5): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (6): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (7): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (8): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (9): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (10): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (11): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (12): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (13): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (14): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (15): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (16): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (17): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (18): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (19): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (20): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (21): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (22): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n        (23): Block(\n          (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (attn): Attention(\n            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n            (attn_drop): Dropout(p=0.0, inplace=False)\n            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (proj_drop): Dropout(p=0.0, inplace=False)\n          )\n          (drop_path): Identity()\n          (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n          (mlp): Mlp(\n            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n            (act): GELU()\n            (drop1): Dropout(p=0.0, inplace=False)\n            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n            (drop2): Dropout(p=0.0, inplace=False)\n          )\n        )\n      )\n      (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n      (pre_logits): Identity()\n      (head): Linear(in_features=1024, out_features=1000, bias=True)\n    )\n    (act_postprocess1): Sequential(\n      (0): ProjectReadout(\n        (project): Sequential(\n          (0): Linear(in_features=2048, out_features=1024, bias=True)\n          (1): GELU()\n        )\n      )\n      (1): Transpose()\n      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n      (3): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n      (4): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(4, 4))\n    )\n    (act_postprocess2): Sequential(\n      (0): ProjectReadout(\n        (project): Sequential(\n          (0): Linear(in_features=2048, out_features=1024, bias=True)\n          (1): GELU()\n        )\n      )\n      (1): Transpose()\n      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n      (3): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n      (4): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n    )\n    (act_postprocess3): Sequential(\n      (0): ProjectReadout(\n        (project): Sequential(\n          (0): Linear(in_features=2048, out_features=1024, bias=True)\n          (1): GELU()\n        )\n      )\n      (1): Transpose()\n      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (act_postprocess4): Sequential(\n      (0): ProjectReadout(\n        (project): Sequential(\n          (0): Linear(in_features=2048, out_features=1024, bias=True)\n          (1): GELU()\n        )\n      )\n      (1): Transpose()\n      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n      (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n      (4): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n    )\n  )\n  (scratch): Module(\n    (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (layer3_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (layer4_rn): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (refinenet1): FeatureFusionBlock_custom(\n      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n      (resConfUnit1): ResidualConvUnit_custom(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (activation): ReLU()\n        (skip_add): FloatFunctional(\n          (activation_post_process): Identity()\n        )\n      )\n      (resConfUnit2): ResidualConvUnit_custom(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (activation): ReLU()\n        (skip_add): FloatFunctional(\n          (activation_post_process): Identity()\n        )\n      )\n      (skip_add): FloatFunctional(\n        (activation_post_process): Identity()\n      )\n    )\n    (refinenet2): FeatureFusionBlock_custom(\n      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n      (resConfUnit1): ResidualConvUnit_custom(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (activation): ReLU()\n        (skip_add): FloatFunctional(\n          (activation_post_process): Identity()\n        )\n      )\n      (resConfUnit2): ResidualConvUnit_custom(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (activation): ReLU()\n        (skip_add): FloatFunctional(\n          (activation_post_process): Identity()\n        )\n      )\n      (skip_add): FloatFunctional(\n        (activation_post_process): Identity()\n      )\n    )\n    (refinenet3): FeatureFusionBlock_custom(\n      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n      (resConfUnit1): ResidualConvUnit_custom(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (activation): ReLU()\n        (skip_add): FloatFunctional(\n          (activation_post_process): Identity()\n        )\n      )\n      (resConfUnit2): ResidualConvUnit_custom(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (activation): ReLU()\n        (skip_add): FloatFunctional(\n          (activation_post_process): Identity()\n        )\n      )\n      (skip_add): FloatFunctional(\n        (activation_post_process): Identity()\n      )\n    )\n    (refinenet4): FeatureFusionBlock_custom(\n      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n      (resConfUnit1): ResidualConvUnit_custom(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (activation): ReLU()\n        (skip_add): FloatFunctional(\n          (activation_post_process): Identity()\n        )\n      )\n      (resConfUnit2): ResidualConvUnit_custom(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        (activation): ReLU()\n        (skip_add): FloatFunctional(\n          (activation_post_process): Identity()\n        )\n      )\n      (skip_add): FloatFunctional(\n        (activation_post_process): Identity()\n      )\n    )\n    (output_conv): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): Interpolate()\n      (2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (3): ReLU(inplace=True)\n      (4): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n      (5): ReLU(inplace=True)\n      (6): Identity()\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"polyp_dir='../input/sun-segmented/mask_123'\ncases_less_5=[]\nfor idx in range(less_more_data.shape[0]):\n    case=less_more_data[less_more_data.columns[0]][idx]\n    case='case'+str(case)\n    case=polyp_dir+'/'+case\n    img=cv2.imread(case)\n    \n    cases_less_5.append(case)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:36:53.332164Z","iopub.execute_input":"2022-07-03T22:36:53.332541Z","iopub.status.idle":"2022-07-03T22:36:53.417017Z","shell.execute_reply.started":"2022-07-03T22:36:53.332506Z","shell.execute_reply":"2022-07-03T22:36:53.416181Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:36:53.418395Z","iopub.execute_input":"2022-07-03T22:36:53.419002Z","iopub.status.idle":"2022-07-03T22:36:53.423662Z","shell.execute_reply.started":"2022-07-03T22:36:53.418948Z","shell.execute_reply":"2022-07-03T22:36:53.422420Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"images_less_5=[]\nfor idx,x in tqdm(enumerate(cases_less_5)):\n    case=cases_less_5[idx]\n    try: \n        items= os.listdir(case)\n    \n        for index in range(len(items)):\n            img=cv2.imread(case+'/'+items[index])\n            if img.max()==0:\n                continue\n            else:\n                images_less_5.append(case+'/'+items[index])\n    except:\n        continue","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:36:53.425219Z","iopub.execute_input":"2022-07-03T22:36:53.426103Z","iopub.status.idle":"2022-07-03T22:37:44.232047Z","shell.execute_reply.started":"2022-07-03T22:36:53.426067Z","shell.execute_reply":"2022-07-03T22:37:44.231031Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"33it [00:50,  1.54s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"images_less_5[:2]","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:37:44.233477Z","iopub.execute_input":"2022-07-03T22:37:44.234059Z","iopub.status.idle":"2022-07-03T22:37:44.241515Z","shell.execute_reply.started":"2022-07-03T22:37:44.234018Z","shell.execute_reply":"2022-07-03T22:37:44.240501Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"['../input/sun-segmented/mask_123/case3/case_M_20181004093748_0U62372100445348_1_001_001-1_a4_ayy_image0163.png',\n '../input/sun-segmented/mask_123/case3/case_M_20181004093748_0U62372100445348_1_001_001-1_a4_ayy_image0099.png']"},"metadata":{}}]},{"cell_type":"code","source":"cases_more_5=[]\npolyp_dir='../input/sun-segmented/mask_123'\nfor idx in range(less_more_data.shape[0]):\n    case=less_more_data[less_more_data.columns[1]][idx]\n    try:\n        case=int(case)\n        case='case'+str(case)\n        case=polyp_dir+'/'+case\n        cases_more_5.append(case)\n    except:\n        pass\n  ","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:37:44.242906Z","iopub.execute_input":"2022-07-03T22:37:44.243832Z","iopub.status.idle":"2022-07-03T22:37:44.252558Z","shell.execute_reply.started":"2022-07-03T22:37:44.243795Z","shell.execute_reply":"2022-07-03T22:37:44.251369Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"images_more_5=[]\nfor idx,x in tqdm(enumerate(cases_more_5)):\n    case=cases_more_5[idx]\n    try: \n        items= os.listdir(case)\n    \n        for index in range(len(items)):\n            img=cv2.imread(case+'/'+items[index])\n            if img.max()==0:\n                continue\n            else:\n                images_more_5.append(case+'/'+items[index])\n    except:\n        continue","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:37:44.254705Z","iopub.execute_input":"2022-07-03T22:37:44.255585Z","iopub.status.idle":"2022-07-03T22:39:40.251472Z","shell.execute_reply.started":"2022-07-03T22:37:44.255548Z","shell.execute_reply":"2022-07-03T22:39:40.249909Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"32it [01:55,  3.62s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"len( images_more_5),len(images_less_5)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:40.256506Z","iopub.execute_input":"2022-07-03T22:39:40.256779Z","iopub.status.idle":"2022-07-03T22:39:40.263777Z","shell.execute_reply.started":"2022-07-03T22:39:40.256753Z","shell.execute_reply":"2022-07-03T22:39:40.262654Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"(17398, 5967)"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n_,images_more=train_test_split(images_more_5,random_state=42,test_size=0.4)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:40.265231Z","iopub.execute_input":"2022-07-03T22:39:40.266268Z","iopub.status.idle":"2022-07-03T22:39:40.559083Z","shell.execute_reply.started":"2022-07-03T22:39:40.266231Z","shell.execute_reply":"2022-07-03T22:39:40.558145Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"len(images_more)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:40.560390Z","iopub.execute_input":"2022-07-03T22:39:40.560747Z","iopub.status.idle":"2022-07-03T22:39:40.567966Z","shell.execute_reply.started":"2022-07-03T22:39:40.560711Z","shell.execute_reply":"2022-07-03T22:39:40.566950Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"6960"},"metadata":{}}]},{"cell_type":"code","source":"#Assembling into a dataframe\nPolyp_Data_More=pd.DataFrame(\n    {\n        \"images\":images_more,\n        \"label\":1\n    }\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:40.569619Z","iopub.execute_input":"2022-07-03T22:39:40.570682Z","iopub.status.idle":"2022-07-03T22:39:40.579033Z","shell.execute_reply.started":"2022-07-03T22:39:40.570636Z","shell.execute_reply":"2022-07-03T22:39:40.577925Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"Polyp_Data_Less=pd.DataFrame(\n    {\n        \"images\":images_less_5,\n        \"label\":0\n    }\n)\nPolyp_Data_Less.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:40.580618Z","iopub.execute_input":"2022-07-03T22:39:40.581140Z","iopub.status.idle":"2022-07-03T22:39:40.595879Z","shell.execute_reply.started":"2022-07-03T22:39:40.581104Z","shell.execute_reply":"2022-07-03T22:39:40.594964Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"                                              images  label\n0  ../input/sun-segmented/mask_123/case3/case_M_2...      0\n1  ../input/sun-segmented/mask_123/case3/case_M_2...      0\n2  ../input/sun-segmented/mask_123/case3/case_M_2...      0\n3  ../input/sun-segmented/mask_123/case3/case_M_2...      0\n4  ../input/sun-segmented/mask_123/case3/case_M_2...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>images</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>../input/sun-segmented/mask_123/case3/case_M_2...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>../input/sun-segmented/mask_123/case3/case_M_2...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>../input/sun-segmented/mask_123/case3/case_M_2...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>../input/sun-segmented/mask_123/case3/case_M_2...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>../input/sun-segmented/mask_123/case3/case_M_2...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"Polyp_Data=pd.concat([Polyp_Data_Less,Polyp_Data_More],ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:40.597438Z","iopub.execute_input":"2022-07-03T22:39:40.597802Z","iopub.status.idle":"2022-07-03T22:39:40.606601Z","shell.execute_reply.started":"2022-07-03T22:39:40.597768Z","shell.execute_reply":"2022-07-03T22:39:40.605680Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nPolyp_Train,Polyp_Test=train_test_split(Polyp_Data,test_size=0.3,random_state=42,)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:40.608249Z","iopub.execute_input":"2022-07-03T22:39:40.608681Z","iopub.status.idle":"2022-07-03T22:39:40.620602Z","shell.execute_reply.started":"2022-07-03T22:39:40.608646Z","shell.execute_reply":"2022-07-03T22:39:40.619615Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"Polyp_Valid,Polyp_Test=train_test_split(Polyp_Test,test_size=0.5,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:40.622636Z","iopub.execute_input":"2022-07-03T22:39:40.622962Z","iopub.status.idle":"2022-07-03T22:39:40.630559Z","shell.execute_reply.started":"2022-07-03T22:39:40.622935Z","shell.execute_reply":"2022-07-03T22:39:40.629641Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"Polyp_Train = Polyp_Train.reset_index()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:40.641357Z","iopub.execute_input":"2022-07-03T22:39:40.642114Z","iopub.status.idle":"2022-07-03T22:39:40.652524Z","shell.execute_reply.started":"2022-07-03T22:39:40.642080Z","shell.execute_reply":"2022-07-03T22:39:40.651398Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"Polyp_Valid=Polyp_Valid.reset_index()\nPolyp_Valid.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:40.653905Z","iopub.execute_input":"2022-07-03T22:39:40.654374Z","iopub.status.idle":"2022-07-03T22:39:40.667658Z","shell.execute_reply.started":"2022-07-03T22:39:40.654323Z","shell.execute_reply":"2022-07-03T22:39:40.666725Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"   index                                             images  label\n0   3615  ../input/sun-segmented/mask_123/case48/case_M_...      0\n1   7371  ../input/sun-segmented/mask_123/case24/case_M_...      1\n2   3448  ../input/sun-segmented/mask_123/case34/case_M_...      0\n3   7237  ../input/sun-segmented/mask_123/case32/case_M_...      1\n4   5666  ../input/sun-segmented/mask_123/case88/case_M_...      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>images</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3615</td>\n      <td>../input/sun-segmented/mask_123/case48/case_M_...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7371</td>\n      <td>../input/sun-segmented/mask_123/case24/case_M_...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3448</td>\n      <td>../input/sun-segmented/mask_123/case34/case_M_...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7237</td>\n      <td>../input/sun-segmented/mask_123/case32/case_M_...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5666</td>\n      <td>../input/sun-segmented/mask_123/case88/case_M_...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"Polyp_Test=Polyp_Test.reset_index()\nPolyp_Test.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:40.669283Z","iopub.execute_input":"2022-07-03T22:39:40.669707Z","iopub.status.idle":"2022-07-03T22:39:40.682613Z","shell.execute_reply.started":"2022-07-03T22:39:40.669645Z","shell.execute_reply":"2022-07-03T22:39:40.681471Z"},"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"   index                                             images  label\n0   5872  ../input/sun-segmented/mask_123/case100/case_M...      0\n1   9322  ../input/sun-segmented/mask_123/case61/case_M_...      1\n2   9584  ../input/sun-segmented/mask_123/case50/case_M_...      1\n3    511  ../input/sun-segmented/mask_123/case10/case_M_...      0\n4  12229  ../input/sun-segmented/mask_123/case37/case_M_...      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>images</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5872</td>\n      <td>../input/sun-segmented/mask_123/case100/case_M...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9322</td>\n      <td>../input/sun-segmented/mask_123/case61/case_M_...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>9584</td>\n      <td>../input/sun-segmented/mask_123/case50/case_M_...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>511</td>\n      <td>../input/sun-segmented/mask_123/case10/case_M_...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12229</td>\n      <td>../input/sun-segmented/mask_123/case37/case_M_...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from collections import defaultdict\nimport copy\nimport random\nimport os\nimport shutil\nfrom urllib.request import urlretrieve\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport torch\nimport torch.backends.cudnn as cudnn\nimport torch.nn as nn\nimport torch.optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.models as models\ncudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:40.684206Z","iopub.execute_input":"2022-07-03T22:39:40.684555Z","iopub.status.idle":"2022-07-03T22:39:41.569574Z","shell.execute_reply.started":"2022-07-03T22:39:40.684519Z","shell.execute_reply":"2022-07-03T22:39:41.568612Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class PolypDataset(Dataset):\n    def __init__(self,images_dataframe,transform=None):\n        self.image_paths=images_dataframe\n        self.transform=transform\n    def __len__(self):\n        return self.image_paths.shape[0]\n    def __getitem__(self,idx):\n        image_filepath=(self.image_paths['images'][idx])\n        #print(self.image_paths['images'][idx])\n        #print(image_filepath)\n        mask_image=cv2.imread(image_filepath,cv2.IMREAD_GRAYSCALE)\n        req_img_1=image_filepath.split('/')[4]\n        req_img_2=image_filepath.split('/')[5]\n        req_img='/'+req_img_1+'/'+req_img_2\n        req_img='../input/sun-polyps/Polyps/Polyps'+req_img\n        req_img='..'+req_img.split('.')[2]+'.jpg'\n        #print(req_img)\n        img=cv2.imread(req_img)\n        image=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        resized_image=cv2.resize(image,(224,224))\n        input_batch = transform(resized_image).to(device)\n        with torch.no_grad():\n            prediction = midas(input_batch)\n\n            prediction = torch.nn.functional.interpolate(\n            prediction.unsqueeze(1),\n            size=img.shape[:2],\n            mode=\"bicubic\",\n            align_corners=False,\n           ).squeeze()\n  \n        output = prediction.cpu().numpy()\n        \n        '''for row in range(mask_image.shape[0]):\n            for col in range(mask_image.shape[1]):\n                mask_image[row][col]=output[row][col]\n        '''\n       \n        for row in range(mask_image.shape[0]):\n            for col in range(mask_image.shape[1]):\n                if mask_image[row][col]==255:\n                    mask_image[row][col]=output[row][col]\n                   \n        \n        label=self.image_paths['label'][idx]\n        mask=mask_image\n        mask=mask/255.\n        if self.transform is not None:\n            mask=self.transform(image=mask)[\"image\"]\n        return mask,label","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:41.571205Z","iopub.execute_input":"2022-07-03T22:39:41.571566Z","iopub.status.idle":"2022-07-03T22:39:41.586447Z","shell.execute_reply.started":"2022-07-03T22:39:41.571529Z","shell.execute_reply":"2022-07-03T22:39:41.585399Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"train_transform = A.Compose(\n    [\n        ToTensorV2(),\n    ]\n)\ntrain_dataset = PolypDataset(images_dataframe=Polyp_Train, transform=train_transform)\nval_transform = A.Compose(\n    [\n        ToTensorV2(),\n    ]\n)\nval_dataset = PolypDataset(images_dataframe=Polyp_Valid, transform=val_transform)\ntest_transform = A.Compose(\n    [\n        ToTensorV2(),\n    ]\n)\ntest_dataset = PolypDataset(images_dataframe=Polyp_Test, transform=test_transform)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:41.587838Z","iopub.execute_input":"2022-07-03T22:39:41.588429Z","iopub.status.idle":"2022-07-03T22:39:41.600753Z","shell.execute_reply.started":"2022-07-03T22:39:41.588386Z","shell.execute_reply":"2022-07-03T22:39:41.599638Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"class MetricMonitor:\n    def __init__(self, float_precision=3):\n        self.float_precision = float_precision\n        self.reset()\n\n    def reset(self):\n        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n\n    def update(self, metric_name, val):\n        metric = self.metrics[metric_name]\n\n        metric[\"val\"] += val\n        metric[\"count\"] += 1\n        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n\n    def __str__(self):\n        return \" | \".join(\n            [\n                \"{metric_name}: {avg:.{float_precision}f}\".format(\n                    metric_name=metric_name, avg=metric[\"avg\"], float_precision=self.float_precision\n                )\n                for (metric_name, metric) in self.metrics.items()\n            ]\n        )","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:41.602122Z","iopub.execute_input":"2022-07-03T22:39:41.602550Z","iopub.status.idle":"2022-07-03T22:39:41.615040Z","shell.execute_reply.started":"2022-07-03T22:39:41.602513Z","shell.execute_reply":"2022-07-03T22:39:41.614032Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"# Model Architecture","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nclass BinaryNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1=nn.Conv2d(1,16,kernel_size=3,padding=1,stride=1)\n        self.relu=nn.ReLU(inplace=True)\n        self.maxpool1=nn.MaxPool2d(kernel_size=2,stride=2)\n        self.batch1=nn.BatchNorm2d(16)\n        self.conv2=nn.Conv2d(16,32,kernel_size=3,padding=1,stride=1)\n        self.maxpool2=nn.MaxPool2d(kernel_size=2,stride=2)\n        self.batch2=nn.BatchNorm2d(32)\n        self.linear1=nn.Linear(56*56*32,64)\n        self.linear2=nn.Linear(64,1)\n\n    def forward(self,x):\n        out=self.conv1(x)\n        out=self.batch1(out)\n        out=self.relu(out)\n        out=self.maxpool1(out)\n        out=self.conv2(out)\n        out=self.batch2(out)\n        out=self.relu(out)\n        out=self.maxpool2(out)\n        out=out.view(-1,56*56*32)\n        out=self.linear1(out)\n        out=self.relu(out)\n        out=self.linear2(out)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:41.616325Z","iopub.execute_input":"2022-07-03T22:39:41.616810Z","iopub.status.idle":"2022-07-03T22:39:41.629893Z","shell.execute_reply.started":"2022-07-03T22:39:41.616775Z","shell.execute_reply":"2022-07-03T22:39:41.628843Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"net=BinaryNet()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:41.631126Z","iopub.execute_input":"2022-07-03T22:39:41.631570Z","iopub.status.idle":"2022-07-03T22:39:41.700145Z","shell.execute_reply.started":"2022-07-03T22:39:41.631533Z","shell.execute_reply":"2022-07-03T22:39:41.699184Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"params = {\n    \"device\": \"cuda\",\n    \"lr\": 0.001,\n    \"batch_size\": 32,\n    \"num_workers\": 4,\n    \"epochs\": 60,\n}","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:41.705354Z","iopub.execute_input":"2022-07-03T22:39:41.705630Z","iopub.status.idle":"2022-07-03T22:39:41.711116Z","shell.execute_reply.started":"2022-07-03T22:39:41.705603Z","shell.execute_reply":"2022-07-03T22:39:41.709891Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"model = net\nmodel = model.to(params[\"device\"])\ncriterion = nn.BCEWithLogitsLoss().to(params[\"device\"])\noptimizer = torch.optim.Adam(model.parameters(), lr=params[\"lr\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:41.712926Z","iopub.execute_input":"2022-07-03T22:39:41.713623Z","iopub.status.idle":"2022-07-03T22:39:41.728585Z","shell.execute_reply.started":"2022-07-03T22:39:41.713587Z","shell.execute_reply":"2022-07-03T22:39:41.727665Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(\n    train_dataset, batch_size=params[\"batch_size\"], shuffle=True, pin_memory=True,\n)\nval_loader = DataLoader(\n    val_dataset, batch_size=params[\"batch_size\"], shuffle=False, pin_memory=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:41.730608Z","iopub.execute_input":"2022-07-03T22:39:41.730945Z","iopub.status.idle":"2022-07-03T22:39:41.738075Z","shell.execute_reply.started":"2022-07-03T22:39:41.730911Z","shell.execute_reply":"2022-07-03T22:39:41.736748Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"test_loader = DataLoader(\n    test_dataset, batch_size=params[\"batch_size\"], shuffle=False, pin_memory=True,\n)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:41.739309Z","iopub.execute_input":"2022-07-03T22:39:41.740373Z","iopub.status.idle":"2022-07-03T22:39:41.748164Z","shell.execute_reply.started":"2022-07-03T22:39:41.740323Z","shell.execute_reply":"2022-07-03T22:39:41.747249Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def train(train_loader, model, criterion, optimizer, epoch, params):\n    metric_monitor = MetricMonitor()\n    model.train()\n    stream = tqdm(train_loader)\n    for i, (images, target) in enumerate(stream, start=1):\n        images = images.to(params[\"device\"], non_blocking=True)\n        images=images.float()\n        target = target.to(params[\"device\"], non_blocking=True).float().view(-1, 1)\n        output = model(images)\n        loss = criterion(output, target)\n        accuracy = calculate_accuracy(output, target)\n        metric_monitor.update(\"Loss\", loss.item())\n        metric_monitor.update(\"Accuracy\", accuracy)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        stream.set_description(\n            \"Epoch: {epoch}. Train.      {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n        )","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:41.749424Z","iopub.execute_input":"2022-07-03T22:39:41.749856Z","iopub.status.idle":"2022-07-03T22:39:41.760095Z","shell.execute_reply.started":"2022-07-03T22:39:41.749817Z","shell.execute_reply":"2022-07-03T22:39:41.759060Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def validate(val_loader, model, criterion, epoch, params):\n    metric_monitor = MetricMonitor()\n    model.eval()\n    stream = tqdm(val_loader)\n    with torch.no_grad():\n        for i, (images, target) in enumerate(stream, start=1):\n            images = images.to(params[\"device\"], non_blocking=True)\n            images=images.float()\n            target = target.to(params[\"device\"], non_blocking=True).float().view(-1, 1)\n            output = model(images)\n            loss = criterion(output, target)\n            accuracy = calculate_accuracy(output, target)\n\n            metric_monitor.update(\"Loss\", loss.item())\n            metric_monitor.update(\"Accuracy\", accuracy)\n            stream.set_description(\n                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(epoch=epoch, metric_monitor=metric_monitor)\n            )","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:41.761521Z","iopub.execute_input":"2022-07-03T22:39:41.762163Z","iopub.status.idle":"2022-07-03T22:39:41.773553Z","shell.execute_reply.started":"2022-07-03T22:39:41.762126Z","shell.execute_reply":"2022-07-03T22:39:41.772289Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"def calculate_accuracy(output, target):\n    output = torch.sigmoid(output) >= 0.5\n    target = target == 1.0\n    return torch.true_divide((target == output).sum(dim=0), output.size(0)).item()","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:41.775069Z","iopub.execute_input":"2022-07-03T22:39:41.775692Z","iopub.status.idle":"2022-07-03T22:39:41.783700Z","shell.execute_reply.started":"2022-07-03T22:39:41.775647Z","shell.execute_reply":"2022-07-03T22:39:41.782740Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1, params[\"epochs\"] + 1):\n    train(train_loader, model, criterion, optimizer, epoch, params)\n    validate(val_loader, model, criterion, epoch, params)","metadata":{"execution":{"iopub.status.busy":"2022-07-03T22:39:41.786328Z","iopub.execute_input":"2022-07-03T22:39:41.786739Z","iopub.status.idle":"2022-07-04T08:09:53.458055Z","shell.execute_reply.started":"2022-07-03T22:39:41.786702Z","shell.execute_reply":"2022-07-04T08:09:53.456469Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"Epoch: 1. Train.      Loss: 0.691 | Accuracy: 0.735: 100%|██████████| 283/283 [40:16<00:00,  8.54s/it]\nEpoch: 1. Validation. Loss: 0.509 | Accuracy: 0.752: 100%|██████████| 61/61 [08:37<00:00,  8.49s/it]\nEpoch: 2. Train.      Loss: 0.420 | Accuracy: 0.805: 100%|██████████| 283/283 [39:02<00:00,  8.28s/it]\nEpoch: 2. Validation. Loss: 0.461 | Accuracy: 0.785: 100%|██████████| 61/61 [08:17<00:00,  8.16s/it]\nEpoch: 3. Train.      Loss: 0.343 | Accuracy: 0.850: 100%|██████████| 283/283 [38:54<00:00,  8.25s/it]\nEpoch: 3. Validation. Loss: 1.053 | Accuracy: 0.577: 100%|██████████| 61/61 [08:23<00:00,  8.25s/it]\nEpoch: 4. Train.      Loss: 0.284 | Accuracy: 0.876: 100%|██████████| 283/283 [39:01<00:00,  8.27s/it]\nEpoch: 4. Validation. Loss: 0.572 | Accuracy: 0.750: 100%|██████████| 61/61 [08:20<00:00,  8.21s/it]\nEpoch: 5. Train.      Loss: 0.244 | Accuracy: 0.896: 100%|██████████| 283/283 [38:59<00:00,  8.27s/it]\nEpoch: 5. Validation. Loss: 0.515 | Accuracy: 0.790: 100%|██████████| 61/61 [08:20<00:00,  8.21s/it]\nEpoch: 6. Train.      Loss: 0.184 | Accuracy: 0.924: 100%|██████████| 283/283 [38:58<00:00,  8.26s/it]\nEpoch: 6. Validation. Loss: 0.587 | Accuracy: 0.783: 100%|██████████| 61/61 [08:20<00:00,  8.21s/it]\nEpoch: 7. Train.      Loss: 0.135 | Accuracy: 0.948: 100%|██████████| 283/283 [38:57<00:00,  8.26s/it]\nEpoch: 7. Validation. Loss: 1.153 | Accuracy: 0.694: 100%|██████████| 61/61 [08:20<00:00,  8.20s/it]\nEpoch: 8. Train.      Loss: 0.118 | Accuracy: 0.955: 100%|██████████| 283/283 [38:56<00:00,  8.25s/it]\nEpoch: 8. Validation. Loss: 0.830 | Accuracy: 0.767: 100%|██████████| 61/61 [08:21<00:00,  8.22s/it]\nEpoch: 9. Train.      Loss: 0.075 | Accuracy: 0.973: 100%|██████████| 283/283 [39:05<00:00,  8.29s/it]\nEpoch: 9. Validation. Loss: 0.998 | Accuracy: 0.756: 100%|██████████| 61/61 [08:21<00:00,  8.23s/it]\nEpoch: 10. Train.      Loss: 0.064 | Accuracy: 0.978: 100%|██████████| 283/283 [39:01<00:00,  8.27s/it]\nEpoch: 10. Validation. Loss: 0.921 | Accuracy: 0.767: 100%|██████████| 61/61 [08:20<00:00,  8.20s/it]\nEpoch: 11. Train.      Loss: 0.051 | Accuracy: 0.984: 100%|██████████| 283/283 [38:58<00:00,  8.26s/it]\nEpoch: 11. Validation. Loss: 1.349 | Accuracy: 0.730: 100%|██████████| 61/61 [08:18<00:00,  8.18s/it]\nEpoch: 12. Train.      Loss: 0.051 | Accuracy: 0.985: 100%|██████████| 283/283 [38:55<00:00,  8.25s/it]\nEpoch: 12. Validation. Loss: 1.054 | Accuracy: 0.772: 100%|██████████| 61/61 [08:20<00:00,  8.20s/it]\nEpoch: 13. Train.      Loss: 0.015 | Accuracy: 1.000:   1%|▏         | 4/283 [00:40<46:38, 10.03s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/3850510899.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_33/3139698688.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, params)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_33/4146271996.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0minput_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresized_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmidas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             prediction = torch.nn.functional.interpolate(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/torch/hub/intel-isl_MiDaS_master/midas/dpt_depth.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/torch/hub/intel-isl_MiDaS_master/midas/dpt_depth.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels_last\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mlayer_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_vit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mlayer_1_rn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscratch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1_rn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/torch/hub/intel-isl_MiDaS_master/midas/vit.py\u001b[0m in \u001b[0;36mforward_vit\u001b[0;34m(pretrained, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mglob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_flex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mlayer_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/.cache/torch/hub/intel-isl_MiDaS_master/midas/vit.py\u001b[0m in \u001b[0;36mforward_flex\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mblk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbw_hook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_input_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1129\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/timm/models/vision_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_full_backward_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1172\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"pt='./model_simple.pt'\ntorch.save(model,pt)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T08:10:05.754854Z","iopub.execute_input":"2022-07-04T08:10:05.756036Z","iopub.status.idle":"2022-07-04T08:10:05.847013Z","shell.execute_reply.started":"2022-07-04T08:10:05.755967Z","shell.execute_reply":"2022-07-04T08:10:05.845959Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"#Saving model with state_dict:\npath='./model_simple_state_dict.pt'\ntorch.save(model.state_dict(),path)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T09:01:48.233947Z","iopub.execute_input":"2022-07-04T09:01:48.234450Z","iopub.status.idle":"2022-07-04T09:01:48.331859Z","shell.execute_reply.started":"2022-07-04T09:01:48.234406Z","shell.execute_reply":"2022-07-04T09:01:48.330550Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"#Running on test dataset\nvalidate(test_loader, model, criterion,1, params)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T08:11:14.570040Z","iopub.execute_input":"2022-07-04T08:11:14.570642Z","iopub.status.idle":"2022-07-04T08:20:02.823377Z","shell.execute_reply.started":"2022-07-04T08:11:14.570605Z","shell.execute_reply":"2022-07-04T08:20:02.822348Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stderr","text":"Epoch: 1. Validation. Loss: 1.022 | Accuracy: 0.783: 100%|██████████| 61/61 [08:48<00:00,  8.66s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"img=torch.tensor([[16],[1]])","metadata":{"execution":{"iopub.status.busy":"2022-07-04T08:21:10.943328Z","iopub.execute_input":"2022-07-04T08:21:10.943670Z","iopub.status.idle":"2022-07-04T08:21:10.949249Z","shell.execute_reply.started":"2022-07-04T08:21:10.943642Z","shell.execute_reply":"2022-07-04T08:21:10.948179Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"img=torch.squeeze(img)\nimg.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-04T08:23:44.901721Z","iopub.execute_input":"2022-07-04T08:23:44.902384Z","iopub.status.idle":"2022-07-04T08:23:44.911021Z","shell.execute_reply.started":"2022-07-04T08:23:44.902334Z","shell.execute_reply":"2022-07-04T08:23:44.910011Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"torch.Size([2])"},"metadata":{}}]},{"cell_type":"code","source":"model.eval()\npreds=[]\ntargets=[]\nwith torch.no_grad():\n    for data,target in test_loader:\n        data,target=data.to(device),target.to(device)\n        data=data.float()\n        targets.append(target)\n        output=model(data)\n        pred=torch.squeeze(output)\n        preds.append(pred)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-07-04T08:25:30.885851Z","iopub.execute_input":"2022-07-04T08:25:30.886424Z","iopub.status.idle":"2022-07-04T08:33:50.538714Z","shell.execute_reply.started":"2022-07-04T08:25:30.886383Z","shell.execute_reply":"2022-07-04T08:33:50.537632Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"#Sigmoid layer and threshold have been applied to predict","metadata":{"execution":{"iopub.status.busy":"2022-07-04T08:42:57.001584Z","iopub.execute_input":"2022-07-04T08:42:57.002041Z","iopub.status.idle":"2022-07-04T08:42:57.006972Z","shell.execute_reply.started":"2022-07-04T08:42:57.001999Z","shell.execute_reply":"2022-07-04T08:42:57.006042Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"new_preds=[]\n\nfor item in range(len(preds)):\n    for idx in range(len(preds[item])):\n        new_preds.append(preds[item][idx])","metadata":{"execution":{"iopub.status.busy":"2022-07-04T08:43:55.791273Z","iopub.execute_input":"2022-07-04T08:43:55.791606Z","iopub.status.idle":"2022-07-04T08:43:55.803013Z","shell.execute_reply.started":"2022-07-04T08:43:55.791579Z","shell.execute_reply":"2022-07-04T08:43:55.802012Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"new_targets=[]\n\nfor item in range(len(targets)):\n    for idx in range(len(targets[item])):\n        new_targets.append(targets[item][idx])","metadata":{"execution":{"iopub.status.busy":"2022-07-04T08:44:35.212813Z","iopub.execute_input":"2022-07-04T08:44:35.213165Z","iopub.status.idle":"2022-07-04T08:44:35.227307Z","shell.execute_reply.started":"2022-07-04T08:44:35.213135Z","shell.execute_reply":"2022-07-04T08:44:35.226041Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"for idx in range(len(new_targets)):\n    new_targets[idx]=new_targets[idx].cpu()\n    new_preds[idx]=new_preds[idx].cpu()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T08:47:44.301544Z","iopub.execute_input":"2022-07-04T08:47:44.301904Z","iopub.status.idle":"2022-07-04T08:47:44.369287Z","shell.execute_reply.started":"2022-07-04T08:47:44.301868Z","shell.execute_reply":"2022-07-04T08:47:44.368474Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"new_targets=np.array(new_targets)\nnew_preds=np.array(new_preds)\nfor idx in range(new_targets.shape[0]):\n    new_targets[idx]=int(new_targets[idx])\n    new_preds[idx]=int(new_preds[idx])","metadata":{"execution":{"iopub.status.busy":"2022-07-04T08:51:13.856089Z","iopub.execute_input":"2022-07-04T08:51:13.856709Z","iopub.status.idle":"2022-07-04T08:51:13.865212Z","shell.execute_reply.started":"2022-07-04T08:51:13.856668Z","shell.execute_reply":"2022-07-04T08:51:13.864259Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import ConfusionMatrixDisplay\ncm=confusion_matrix(new_targets,new_preds)","metadata":{"execution":{"iopub.status.busy":"2022-07-04T08:56:38.064897Z","iopub.execute_input":"2022-07-04T08:56:38.065967Z","iopub.status.idle":"2022-07-04T08:56:38.072774Z","shell.execute_reply.started":"2022-07-04T08:56:38.065928Z","shell.execute_reply":"2022-07-04T08:56:38.071619Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"cm","metadata":{"execution":{"iopub.status.busy":"2022-07-04T08:56:39.883135Z","iopub.execute_input":"2022-07-04T08:56:39.883585Z","iopub.status.idle":"2022-07-04T08:56:39.891305Z","shell.execute_reply.started":"2022-07-04T08:56:39.883544Z","shell.execute_reply":"2022-07-04T08:56:39.890013Z"},"trusted":true},"execution_count":121,"outputs":[{"execution_count":121,"output_type":"execute_result","data":{"text/plain":"array([[633, 282],\n       [148, 877]])"},"metadata":{}}]},{"cell_type":"code","source":"\ndisp=ConfusionMatrixDisplay(cm)\n\ndisp.plot()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-04T09:00:15.929584Z","iopub.execute_input":"2022-07-04T09:00:15.929947Z","iopub.status.idle":"2022-07-04T09:00:16.123968Z","shell.execute_reply.started":"2022-07-04T09:00:15.929916Z","shell.execute_reply":"2022-07-04T09:00:16.123035Z"},"trusted":true},"execution_count":126,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"# As we can see, our model makes a total of (633+877) predictions correctly. Thus accuracy is 77.83%.\n# Recall is : 75.66%\n# Precision is: 85.56%\n# F1-Score is : 0.8027\n# ","metadata":{}},{"cell_type":"code","source":"#Showing some predictions:\n","metadata":{},"execution_count":null,"outputs":[]}]}